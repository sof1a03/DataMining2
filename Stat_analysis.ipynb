{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "import pandas as pd \n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv(\"train_reviews.csv\")\n",
    "trainsentences = traindf[\"Review\"].values\n",
    "trainlabels = traindf[\"Label\"].values\n",
    "testdf = pd.read_csv(\"test_reviews.csv\")\n",
    "testsentences = testdf[\"Review\"].values\n",
    "testlabels = testdf[\"Label\"].values \n",
    "\n",
    "with open(\"english\", \"r\") as file:\n",
    "    stop_words = set(file.read().splitlines())\n",
    "with open(\"hotel_names.csv\", \"r\") as file:  \n",
    "    hotel_names = set(file.read().splitlines())\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text) \n",
    "    words = text.split()   \n",
    "    words = [word for word in words if word not in stop_words and word not in hotel_names]    \n",
    "    text = ' '.join(words).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "train_sentences_preprocessed = [preprocess_text(sentence) for sentence in trainsentences]\n",
    "test_sentences_preprocessed = [preprocess_text(sentence) for sentence in testsentences]\n",
    "train_df_preprocessed = pd.DataFrame({'Review': train_sentences_preprocessed,'Label': trainlabels})\n",
    "test_df_preprocessed = pd.DataFrame({'Review': test_sentences_preprocessed,'Label': testlabels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsentences = train_df_preprocessed[\"Review\"].values\n",
    "y_train = train_df_preprocessed[\"Label\"].values\n",
    "\n",
    "testsentences = test_df_preprocessed[\"Review\"].values\n",
    "y_test = test_df_preprocessed[\"Label\"].values\n",
    "\n",
    "# Encode labels as integers\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# vectorizing\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1)) # ngram range for specifying unigrams and bigrams (1,1) - unigram, (2,2) - bigram, (1,2) - both\n",
    "X_train = vectorizer.fit_transform(trainsentences)\n",
    "X_test = vectorizer.transform(testsentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_pred, y_test):#, exclude_sentiment=False):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    dict={'accuracy':accuracy, 'precision':precision, 'recall':recall, 'f1':f1}\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and accuracy without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "multinomial_naive_bayes = MultinomialNB(alpha = 1.5, fit_prior = True)\n",
    "multinomial_naive_bayes.fit(X_train, y_train)\n",
    "# predictions\n",
    "y_pred_mb1 = multinomial_naive_bayes.predict(X_test)\n",
    "dict_mb1 = evaluate_model(y_pred_mb1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and accuracy with chi squared test for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['abassador' 'accept' 'accepted' ... 'yunan' 'zone' 'zoo']\n",
      "Test Set Accuracy: 0.85625\n",
      "Precision: 0.8608\n",
      "Recall: 0.8562\n",
      "F1 Score: 0.8558\n"
     ]
    }
   ],
   "source": [
    "# Perform Chi-squared feature selection\n",
    "chi2_selector = SelectKBest(chi2, k=2000) #2000 features perform best\n",
    "X_train_chi2 = chi2_selector.fit_transform(X_train, y_train)\n",
    "X_test_chi2 = chi2_selector.transform(X_test)\n",
    "\n",
    "# Train a Multinomial Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_chi2, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = nb_model.predict(X_test_chi2)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Get the feature names for the selected features\n",
    "selected_feature_indices = chi2_selector.get_support(indices=True)\n",
    "selected_feature_names = vectorizer.get_feature_names_out()[selected_feature_indices]\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Selected Features: {selected_feature_names}\")\n",
    "print(f\"Test Set Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "multinomial_naive_bayes = MultinomialNB( alpha = 0.1, fit_prior = True)\n",
    "multinomial_naive_bayes.fit(X_train_chi2, y_train)\n",
    "# predictions\n",
    "y_pred_mbc2 = multinomial_naive_bayes.predict(X_test_chi2)\n",
    "dict_mbc2 = evaluate_model(y_pred_mbc2, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "logistic_regression = LogisticRegression(penalty='l1', solver='liblinear', C=5)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "# predictions\n",
    "y_pred_l1 = logistic_regression.predict(X_test)\n",
    "dict_l1 = evaluate_model(y_pred_l1, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "decision_tree = DecisionTreeClassifier(ccp_alpha= 0.0, criterion= 'gini', max_depth= 8, min_samples_leaf= 6, min_samples_split= 2, random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "# predictions\n",
    "y_pred_ct1 = decision_tree.predict(X_test)\n",
    "dict_ct1 = evaluate_model(y_pred_ct1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "random_forest = RandomForestClassifier(criterion = 'entropy', max_depth = 10, max_features=\"sqrt\", min_samples_leaf=2, min_samples_split=5, n_estimators=100, random_state = 42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "# predictions\n",
    "y_pred_rf1 = random_forest.predict(X_test)\n",
    "dict_rf1 = evaluate_model(y_pred_rf1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv(\"train_reviews.csv\")\n",
    "trainsentences = traindf[\"Review\"].values\n",
    "trainlabels = traindf[\"Label\"].values\n",
    "testdf = pd.read_csv(\"test_reviews.csv\")\n",
    "testsentences = testdf[\"Review\"].values\n",
    "testlabels = testdf[\"Label\"].values \n",
    "\n",
    "with open(\"english\", \"r\") as file:\n",
    "    stop_words = set(file.read().splitlines())\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text) \n",
    "    words = text.split()   \n",
    "    words = [word for word in words if word not in stop_words]    \n",
    "    text = ' '.join(words).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "train_sentences_preprocessed = [preprocess_text(sentence) for sentence in trainsentences]\n",
    "test_sentences_preprocessed = [preprocess_text(sentence) for sentence in testsentences]\n",
    "train_df_preprocessed = pd.DataFrame({'Review': train_sentences_preprocessed,'Label': trainlabels})\n",
    "test_df_preprocessed = pd.DataFrame({'Review': test_sentences_preprocessed,'Label': testlabels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsentences = train_df_preprocessed[\"Review\"].values\n",
    "y_train = train_df_preprocessed[\"Label\"].values\n",
    "\n",
    "testsentences = test_df_preprocessed[\"Review\"].values\n",
    "y_test = test_df_preprocessed[\"Label\"].values\n",
    "\n",
    "# Encode labels as integers\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# vectorizing\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2)) # ngram range for specifying unigrams and bigrams (1,1) - unigram, (2,2) - bigram, (1,2) - both\n",
    "X_train = vectorizer.fit_transform(trainsentences)\n",
    "X_test = vectorizer.transform(testsentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and accuracy without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "multinomial_naive_bayes = MultinomialNB( alpha = 0.1, fit_prior = True)\n",
    "multinomial_naive_bayes.fit(X_train, y_train)\n",
    "# predictions\n",
    "y_pred_mb2 = multinomial_naive_bayes.predict(X_test)\n",
    "dict_mb2 = evaluate_model(y_pred_mb2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and accuracy with chi squared test for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['able relax' 'accommodate us' 'across street' ... 'young people'\n",
      " 'youre going' 'youre traveler']\n",
      "Test Set Accuracy: 0.725\n",
      "Precision: 0.7370\n",
      "Recall: 0.7250\n",
      "F1 Score: 0.7215\n"
     ]
    }
   ],
   "source": [
    "# Perform Chi-squared feature selection\n",
    "chi2_selector = SelectKBest(chi2, k=2000) #2000 features perform best\n",
    "X_train_chi2 = chi2_selector.fit_transform(X_train, y_train)\n",
    "X_test_chi2 = chi2_selector.transform(X_test)\n",
    "\n",
    "# Train a Multinomial Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_chi2, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = nb_model.predict(X_test_chi2)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Get the feature names for the selected features\n",
    "selected_feature_indices = chi2_selector.get_support(indices=True)\n",
    "selected_feature_names = vectorizer.get_feature_names_out()[selected_feature_indices]\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Selected Features: {selected_feature_names}\")\n",
    "print(f\"Test Set Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "multinomial_naive_bayes = MultinomialNB(alpha = 0.1, fit_prior = True)\n",
    "multinomial_naive_bayes.fit(X_train_chi2, y_train)\n",
    "# predictions\n",
    "y_pred_mbc22 = multinomial_naive_bayes.predict(X_test_chi2)\n",
    "dict_mbc22 = evaluate_model(y_pred_mbc22, y_test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "logistic_regression = LogisticRegression(penalty='l1', solver='liblinear', C=10)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "# predictions\n",
    "y_pred_l2 = logistic_regression.predict(X_test)\n",
    "dict_l2 = evaluate_model(y_pred_l2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "decision_tree = DecisionTreeClassifier(ccp_alpha= 0.0, criterion= 'gini', max_depth= 8, min_samples_leaf= 6, min_samples_split= 2, random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "# predictions\n",
    "y_pred_ct2 = decision_tree.predict(X_test)\n",
    "dict_ct2 = evaluate_model(y_pred_ct2, y_test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "random_forest = RandomForestClassifier(criterion = 'entropy', max_depth = None, max_features=\"sqrt\", min_samples_leaf=2, min_samples_split=2, n_estimators=100, random_state = 42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "# predictions\n",
    "y_pred_rf2 = random_forest.predict(X_test)\n",
    "dict_rf2 = evaluate_model(y_pred_rf2, y_test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistical Analysis** \n",
    "\n",
    "Using Mcnemar to compare the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "#let's remember that we have computed the predictions for the three models:\n",
    "# y_pred_test: single tree\n",
    "# y_pred_test_bagging: bagging\n",
    "# y_pred_test_forest: random forest\n",
    "def contingency_matrics(y_true, pred1, pred2):\n",
    "    # Contingency Table\n",
    "    # Here, we compare both model predictions, not against y_true but against each other\n",
    "    a = np.sum((pred1 == y_true) & (pred2 == y_true))  # Both models correct\n",
    "    b = np.sum((pred1 == y_true) & (pred2 != y_true))  # Model 1 correct, Model 2 incorrect\n",
    "    c = np.sum((pred1 != y_true) & (pred2 == y_true))  # Model 1 incorrect, Model 2 correct\n",
    "    d = np.sum((pred1 != y_true) & (pred2 != y_true))  # Both models incorrect\n",
    "\n",
    "    # Print the contingency table\n",
    "    contingency_matrix = np.array([[a, b], [c, d]])\n",
    "    return contingency_matrix\n",
    "\n",
    "# Helper function to perform McNemar's test and print the contingency table\n",
    "def mcnemar_test(contingency_matrix):\n",
    "    \n",
    "    # Perform McNemar's test (you could also try exact=True for small samples)\n",
    "    mcnemar_r = mcnemar(contingency_matrix, exact=False, correction=True)\n",
    "    chi2 = mcnemar_r.statistic  # Access the test statistic\n",
    "    p_value = mcnemar_r.pvalue  # Access the p-value\n",
    "    return chi2, p_value\n",
    "\n",
    "def single_pairing_test(y_true, pred1, pred2, model_name1, model_name2, n_test):\n",
    "    \"\"\"\n",
    "    Compare three models pairwise using McNemar's test.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: Ground truth labels --> column 'post' from the dataset\n",
    "    - pred1: Predictions from Model 1 \n",
    "    - pred2: Predictions from Model 2\n",
    "\n",
    "    Returns:\n",
    "    - chi-squared statistics and p-values for pairwise comparisons, including a print statement showing if Hâ‚€ is accepted or rejected.\n",
    "    \"\"\"\n",
    "    cont_m=contingency_matrics(y_true, pred1, pred2)\n",
    "    chi2, p_value = mcnemar_test(cont_m)\n",
    "    \n",
    "    print(f'Contingency Table:\\n{cont_m}')\n",
    "    print(f'Chi-squared: {chi2}')\n",
    "    print(f'p-value: {p_value}')\n",
    "    if p_value < 0.05/n_test:\n",
    "        print(\"The difference in performance is statistically significant.\\nReject the null hypothesis.\\n\")\n",
    "        print(f\"This means that {model_name1}'s accuracy is significantly different from {model_name2}'s accuracy.\\n\")\n",
    "    else:\n",
    "        print(\"There's no statistically significant difference in performance.\\nAccept the null hypothesis.\\n\")\n",
    "        print(f\"This means that {model_name1}'s accuracy is no significantly different from {model_name2}'s accuracy.\\n\")\n",
    "    \n",
    "    return cont_m, chi2, p_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram\n",
      "Evaluation Naive Bayes\n",
      "{'accuracy': 0.85, 'precision': np.float64(0.9117647058823529), 'recall': np.float64(0.775), 'f1': np.float64(0.8378378378378378)}\n",
      "Evaluation Logistic Regression\n",
      "{'accuracy': 0.775, 'precision': np.float64(0.8055555555555556), 'recall': np.float64(0.725), 'f1': np.float64(0.7631578947368421)}\n",
      "Evaluation Decision Tree\n",
      "{'accuracy': 0.625, 'precision': np.float64(0.5943396226415094), 'recall': np.float64(0.7875), 'f1': np.float64(0.6774193548387096)}\n",
      "Evaluation Random Forest\n",
      "{'accuracy': 0.8125, 'precision': np.float64(0.7906976744186046), 'recall': np.float64(0.85), 'f1': np.float64(0.8192771084337349)}\n",
      "Bigram\n",
      "Evaluation Naive Bayes\n",
      "{'accuracy': 0.7625, 'precision': np.float64(0.8088235294117647), 'recall': np.float64(0.6875), 'f1': np.float64(0.7432432432432432)}\n",
      "Evaluation Logistic Regression\n",
      "{'accuracy': 0.65, 'precision': np.float64(0.6016949152542372), 'recall': np.float64(0.8875), 'f1': np.float64(0.7171717171717171)}\n",
      "Evaluation Decision Tree\n",
      "{'accuracy': 0.60625, 'precision': np.float64(0.5648854961832062), 'recall': np.float64(0.925), 'f1': np.float64(0.7014218009478673)}\n",
      "Evaluation Random Forest\n",
      "{'accuracy': 0.7125, 'precision': np.float64(0.646551724137931), 'recall': np.float64(0.9375), 'f1': np.float64(0.7653061224489796)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram\")\n",
    "print(\"Evaluation Naive Bayes\")\n",
    "print(dict_mb1)\n",
    "print(\"Evaluation Logistic Regression\")\n",
    "print(dict_l1)\n",
    "print(\"Evaluation Decision Tree\")\n",
    "print(dict_ct1)\n",
    "print(\"Evaluation Random Forest\")\n",
    "print(dict_rf1)\n",
    "print(\"Bigram\")\n",
    "print(\"Evaluation Naive Bayes\")\n",
    "print(dict_mb2)\n",
    "print(\"Evaluation Logistic Regression\")\n",
    "print(dict_l2)\n",
    "print(\"Evaluation Decision Tree\")\n",
    "print(dict_ct2)\n",
    "print(\"Evaluation Random Forest\")\n",
    "print(dict_rf2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UNIGRAMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table:\n",
      "[[91 39]\n",
      " [ 9 21]]\n",
      "Chi-squared: 17.520833333333332\n",
      "p-value: 2.8417667670336965e-05\n",
      "The difference in performance is statistically significant.\n",
      "Reject the null hypothesis.\n",
      "\n",
      "This means that Random Forest's accuracy is significantly different from Decision Tree's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[109  21]\n",
      " [ 15  15]]\n",
      "Chi-squared: 0.6944444444444444\n",
      "p-value: 0.40465676192728617\n",
      "There's no statistically significant difference in performance.\n",
      "Accept the null hypothesis.\n",
      "\n",
      "This means that Random Forest's accuracy is no significantly different from Logistic Regression's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[118  12]\n",
      " [ 18  12]]\n",
      "Chi-squared: 0.8333333333333334\n",
      "p-value: 0.3613104285261789\n",
      "There's no statistically significant difference in performance.\n",
      "Accept the null hypothesis.\n",
      "\n",
      "This means that Random Forest's accuracy is no significantly different from Multinomial Naive Bayes's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[115  15]\n",
      " [ 18  12]]\n",
      "Chi-squared: 0.12121212121212122\n",
      "p-value: 0.7277235466695502\n",
      "There's no statistically significant difference in performance.\n",
      "Accept the null hypothesis.\n",
      "\n",
      "This means that Random Forest's accuracy is no significantly different from Multinomial Naive Bayes chi_square's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[81 19]\n",
      " [43 17]]\n",
      "Chi-squared: 8.53225806451613\n",
      "p-value: 0.0034890655619424743\n",
      "The difference in performance is statistically significant.\n",
      "Reject the null hypothesis.\n",
      "\n",
      "This means that Decision Tree's accuracy is significantly different from Logistic Regression's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[89 11]\n",
      " [47 13]]\n",
      "Chi-squared: 21.120689655172413\n",
      "p-value: 4.312468453366182e-06\n",
      "The difference in performance is statistically significant.\n",
      "Reject the null hypothesis.\n",
      "\n",
      "This means that Decision Tree's accuracy is significantly different from Multinomial Naive Bayes's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[85 15]\n",
      " [48 12]]\n",
      "Chi-squared: 16.253968253968253\n",
      "p-value: 5.5393454192927676e-05\n",
      "The difference in performance is statistically significant.\n",
      "Reject the null hypothesis.\n",
      "\n",
      "This means that Decision Tree's accuracy is significantly different from Multinomial Naive Bayes chi_square's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[116   8]\n",
      " [ 20  16]]\n",
      "Chi-squared: 4.321428571428571\n",
      "p-value: 0.03763531378731436\n",
      "There's no statistically significant difference in performance.\n",
      "Accept the null hypothesis.\n",
      "\n",
      "This means that Logistic Regression's accuracy is no significantly different from Multinomial Naive Bayes's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[110  14]\n",
      " [ 23  13]]\n",
      "Chi-squared: 1.7297297297297298\n",
      "p-value: 0.18844541724270242\n",
      "There's no statistically significant difference in performance.\n",
      "Accept the null hypothesis.\n",
      "\n",
      "This means that Logistic Regression's accuracy is no significantly different from Multinomial Naive Bayes chi_square's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[129   7]\n",
      " [  4  20]]\n",
      "Chi-squared: 0.36363636363636365\n",
      "p-value: 0.5464935954065822\n",
      "There's no statistically significant difference in performance.\n",
      "Accept the null hypothesis.\n",
      "\n",
      "This means that Multinomial Naive Bayes's accuracy is no significantly different from Multinomial Naive Bayes chi_square's accuracy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_test=8\n",
    "# Mcnemare test for unigrams\n",
    "cont_m1, chi2_1, p_value_1 = single_pairing_test(y_test, y_pred_rf1, y_pred_ct1, 'Random Forest', 'Decision Tree', n_test)  \n",
    "cont_m2, chi2_2, p_value_2 = single_pairing_test(y_test, y_pred_rf1, y_pred_l1, 'Random Forest', 'Logistic Regression', n_test)\n",
    "cont_mn_test, chi2_n_test, p_value_n_test = single_pairing_test(y_test, y_pred_rf1, y_pred_mb1, 'Random Forest', 'Multinomial Naive Bayes', n_test)\n",
    "cont_mn_test_1, chi2_n_test_1, p_value_n_test_1 = single_pairing_test(y_test, y_pred_rf1, y_pred_mbc2, 'Random Forest', 'Multinomial Naive Bayes chi_square', n_test)\n",
    "cont_m4, chi2_4, p_value_4 = single_pairing_test(y_test, y_pred_ct1, y_pred_l1, 'Decision Tree', 'Logistic Regression', n_test)\n",
    "cont_m5, chi2_5, p_value_5 = single_pairing_test(y_test, y_pred_ct1, y_pred_mb1, 'Decision Tree', 'Multinomial Naive Bayes', n_test)\n",
    "cont_m5_1, chi2_5_1, p_value_5_1 = single_pairing_test(y_test, y_pred_ct1, y_pred_mbc2, 'Decision Tree', 'Multinomial Naive Bayes chi_square', n_test)\n",
    "cont_m6, chi2_6, p_value_6 = single_pairing_test(y_test, y_pred_l1, y_pred_mb1, 'Logistic Regression', 'Multinomial Naive Bayes', n_test)\n",
    "cont_m6_1, chi2_6_1, p_value_6_1 = single_pairing_test(y_test, y_pred_l1, y_pred_mbc2, 'Logistic Regression', 'Multinomial Naive Bayes chi_square', n_test)\n",
    "cont_m7, chi2_7, p_value_7 = single_pairing_test(y_test, y_pred_mb1, y_pred_mbc2, 'Multinomial Naive Bayes', 'Multinomial Naive Bayes chi_square', n_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BIGRAMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table:\n",
      "[[93 21]\n",
      " [ 4 42]]\n",
      "Chi-squared: 10.24\n",
      "p-value: 0.0013742758758316976\n",
      "The difference in performance is statistically significant.\n",
      "Reject the null hypothesis.\n",
      "\n",
      "This means that Random Forest's accuracy is significantly different from Decision Tree's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[96 18]\n",
      " [ 8 38]]\n",
      "Chi-squared: 3.1153846153846154\n",
      "p-value: 0.0775561667436654\n",
      "There's no statistically significant difference in performance.\n",
      "Accept the null hypothesis.\n",
      "\n",
      "This means that Random Forest's accuracy is no significantly different from Logistic Regression's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[92 22]\n",
      " [30 16]]\n",
      "Chi-squared: 0.9423076923076923\n",
      "p-value: 0.33168506805685966\n",
      "There's no statistically significant difference in performance.\n",
      "Accept the null hypothesis.\n",
      "\n",
      "This means that Random Forest's accuracy is no significantly different from Multinomial Naive Bayes's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[83 31]\n",
      " [27 19]]\n",
      "Chi-squared: 0.15517241379310345\n",
      "p-value: 0.6936406217837585\n",
      "There's no statistically significant difference in performance.\n",
      "Accept the null hypothesis.\n",
      "\n",
      "This means that Random Forest's accuracy is no significantly different from Multinomial Naive Bayes chi_square's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[87 10]\n",
      " [17 46]]\n",
      "Chi-squared: 1.3333333333333333\n",
      "p-value: 0.24821307898992026\n",
      "There's no statistically significant difference in performance.\n",
      "Accept the null hypothesis.\n",
      "\n",
      "This means that Decision Tree's accuracy is no significantly different from Logistic Regression's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[74 23]\n",
      " [48 15]]\n",
      "Chi-squared: 8.112676056338028\n",
      "p-value: 0.004395678791103057\n",
      "The difference in performance is statistically significant.\n",
      "Reject the null hypothesis.\n",
      "\n",
      "This means that Decision Tree's accuracy is significantly different from Multinomial Naive Bayes's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[64 33]\n",
      " [46 17]]\n",
      "Chi-squared: 1.8227848101265822\n",
      "p-value: 0.17698215046059831\n",
      "There's no statistically significant difference in performance.\n",
      "Accept the null hypothesis.\n",
      "\n",
      "This means that Decision Tree's accuracy is no significantly different from Multinomial Naive Bayes chi_square's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[84 20]\n",
      " [38 18]]\n",
      "Chi-squared: 4.982758620689655\n",
      "p-value: 0.02560112917755574\n",
      "There's no statistically significant difference in performance.\n",
      "Accept the null hypothesis.\n",
      "\n",
      "This means that Logistic Regression's accuracy is no significantly different from Multinomial Naive Bayes's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[77 27]\n",
      " [33 23]]\n",
      "Chi-squared: 0.4166666666666667\n",
      "p-value: 0.5186050164287255\n",
      "There's no statistically significant difference in performance.\n",
      "Accept the null hypothesis.\n",
      "\n",
      "This means that Logistic Regression's accuracy is no significantly different from Multinomial Naive Bayes chi_square's accuracy.\n",
      "\n",
      "Contingency Table:\n",
      "[[101  21]\n",
      " [  9  29]]\n",
      "Chi-squared: 4.033333333333333\n",
      "p-value: 0.04460971802493953\n",
      "There's no statistically significant difference in performance.\n",
      "Accept the null hypothesis.\n",
      "\n",
      "This means that Multinomial Naive Bayes's accuracy is no significantly different from Multinomial Naive Bayes chi_square's accuracy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_test=10\n",
    "# Mcnemare test for bigrams\n",
    "cont_m1, chi2_1, p_value_1 = single_pairing_test(y_test, y_pred_rf2, y_pred_ct2, 'Random Forest', 'Decision Tree', n_test)  \n",
    "cont_m2, chi2_2, p_value_2 = single_pairing_test(y_test, y_pred_rf2, y_pred_l2, 'Random Forest', 'Logistic Regression', n_test)\n",
    "cont_mn_test, chi2_n_test, p_value_n_test = single_pairing_test(y_test, y_pred_rf2, y_pred_mb2, 'Random Forest', 'Multinomial Naive Bayes', n_test)\n",
    "cont_mn_test_1, chi2_n_test_1, p_value_n_test_1 = single_pairing_test(y_test, y_pred_rf2, y_pred_mbc22, 'Random Forest', 'Multinomial Naive Bayes chi_square', n_test)\n",
    "cont_m4, chi2_4, p_value_4 = single_pairing_test(y_test, y_pred_ct2, y_pred_l2, 'Decision Tree', 'Logistic Regression', n_test)\n",
    "cont_m5, chi2_5, p_value_5 = single_pairing_test(y_test, y_pred_ct2, y_pred_mb2, 'Decision Tree', 'Multinomial Naive Bayes', n_test)\n",
    "cont_m5_1, chi2_5_1, p_value_5_1 = single_pairing_test(y_test, y_pred_ct2, y_pred_mbc22, 'Decision Tree', 'Multinomial Naive Bayes chi_square', n_test)\n",
    "cont_m6, chi2_6, p_value_6 = single_pairing_test(y_test, y_pred_l2, y_pred_mb2, 'Logistic Regression', 'Multinomial Naive Bayes', n_test)\n",
    "cont_m6_1, chi2_6_1, p_value_6_1 = single_pairing_test(y_test, y_pred_l2, y_pred_mbc22, 'Logistic Regression', 'Multinomial Naive Bayes chi_square', n_test)\n",
    "cont_m7, chi2_7, p_value_7 = single_pairing_test(y_test, y_pred_mb2, y_pred_mbc22, 'Multinomial Naive Bayes', 'Multinomial Naive Bayes chi_square', n_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
